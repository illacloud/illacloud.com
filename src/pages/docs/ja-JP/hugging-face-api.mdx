---
title: 顔をハグする API
metaTitle: Hugging Face API に接続
desc: ILLA での Hugging Face API の使い方を学ぶ
tagCategory: doc_menu_hugging_face_api_click
categoryName: 🔨 統合
categoryPriority: 3
postPriority: 1
---

* * *

## <h2 hidden>Hugging Face API</h2>

Hugging Faceは機械学習コミュニティのGithubであり、現在数十万の事前訓練されたモデルと10,000のデータセットが利用可能です。 他の業界の専門家が共有するモデルやデータセットに自由にアクセスしたり、Hugging Faceにモデルをホストしてデプロイしたりできます。

Hugging Faceライブラリで利用可能なモデルのいくつかの例は次のとおりです。

1.  BERT(双方向エンコーダ表現のトランスフォーマー):BERTはGoogleがさまざまなNLPタスクのために開発したトランスベースのモデルです。 言語理解と機械翻訳タスクにおいて、最先端の成果を達成しています。
2.  GPT(Generative Pre-training Transformer):GPTは、OpenAIによって開発された別のトランスベースのモデルです。 これは、主に翻訳やテキスト要約などの言語生成タスクに使用されます。
3.  RoBERTa(ロバスト最適化されたBERT):RoBERTaは、さまざまなNLPタスクでBERTのパフォーマンスを向上させるために開発されたBERTモデルの拡張機能です。
4.  XLNet (eXtraordinary LanguageNet): XLNetは、言語理解タスクにおけるトランスモデルのパフォーマンスを向上させるために、Googleが開発したトランスベースのモデルです。
5.  ALBERT(Lite BERT):ALBERTはNLPタスクで良好なパフォーマンスを維持しながら、より効率的でより速く訓練するように開発されたBERTモデルのバージョンです。

### ILLAビルダーでHugging Faceでできること

Hugging Faceでは、130,000以上の機械学習モデルがパブリックAPIを通じて利用できます。これは[\*\*\[https://hugggingface.co/models\](https://huggingface.co/models)]([https://huggingface.co/models])で無料でテストできます。 さらに、本番シナリオのソリューションが必要な場合は、Hugging Faceの推論エンドポイントを使用することができます。Hugging Faceのエンドポイントは、\[**[https://hugggingface.co/docs/conference-endpoints/index](https://huggingface.co/docs/conference-endpoints/index)](<https://huggingface.co/docs/conference-endpoints/index>**にデプロイしてアクセスできます。

ILLA Builderには、数十の一般的なフロントエンドコンポーネントが用意されており、特定のニーズに基づいてさまざまなフロントエンドインターフェイスを迅速に構築できます。 同時に、ILLAはHugging Faceへの接続を提供し、APIに素早く接続し、リクエストを送信し、返されたデータを受け取ることができます。 APIとフロントエンドコンポーネントを接続することで ユーザーがフロントエンドからコンテンツを入力してAPIに送信できるという要件を実装できます。 APIは、フロントエンドに表示される生成されたコンテンツを返します。

### Hugging Face API リソースを設定します

| プロパティー | 必須 | 説明                                                                    |
| ------ | -- | --------------------------------------------------------------------- |
| 名前     | 必須 | ILLA で表示するリソース名を定義します。                                                |
| トークン   | 必須 | ユーザーアクセスまたは API トークン。 https://huggingface.co/settings/tokensで入手できます。  |

### アクションの設定

| プロパティー   | 必須 | 説明                                                                                                                           |
| -------- | -- | ---------------------------------------------------------------------------------------------------------------------------- |
| モデル ID   | 必須 | モデルを検索: https://huggingface.co/models                                                                                        |
| パラメータの種類 | 必須 | エンドポイントのパラメータタイプ。 たとえば、エンドポイントにテキスト入力が必要な場合は、「inputs」パラメータにテキストを入力します。 エンドポイントにJSON入力が必要な場合は、「inputs」パラメータをJSONまたはキー値で入力します。 |
| パラメータ    | 必須 | パラメータを入力します。 コンポーネントのデータを使用するには {{ componentName.value }} を使用します。                                                            |

# ILLA Builder で Hugging Face を使用する方法

### ステップ1: ILLA Builder上でコンポーネントを使用してUIを構築する

予想される使用シナリオに基づいて、フロントエンドインターフェイスを構築します。 たとえば、商品がテキストを取り込んで画像を出力する場合、input と image コンポーネントを使用できます。 製品がテキストを取り込み、生成されたテキストを出力する場合、入力コンポーネントとテキストコンポーネントを使用できます。

以下の画像は、コンテキストに基づいて質問に答える製品のフロントエンドページの例です。

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi1.png' alt="" />

### ステップ 2: Hugging Face Resourceを作成し、アクションを設定します

アクションリストで [+ 新規] をクリックし、[Hugging Face Inference API] を選択します。

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi2.png' alt="" />

Hugging Faceに接続するには、フォームに入力してください:

名前: ILLA に表示される名前

トークン: Hugging Faceformat@@0(<https://hugggingface.co/settings/tokens>)

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi3.png' alt="" />

アクションを設定する前に、Hugging Faceでモデル情報を確認します。

[Hugging Face Model Page]([https://hugggingface.co/models](https://huggingface.co/models))でモデルを選択してください

例として[deepset/roberta-base-squad2]\([https://hugggingface.co/deepset/roberta-base-squad2](https://huggingface.co/deepset/roberta-base-squad2)を使用しましょう。 詳細ページを入力>デプロイ>推論APIをクリックします。

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi4.png' alt="" />

`inputs`の後のパラメータはILLAで入力すべきものです。 

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi5.png' alt="" />

ILLAビルダーでは、Model IDとParameterを入力します。 上記のモデルを例に挙げると、`inputs`はキーと値のペアであるため、キーと値またはJSONで入力できます。 

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi6.png' alt="" />

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi7.png' alt="" />

また、Hugging Face Inference API 接続を満たすことができるテキスト入力とバイナリ入力もサポートします。

### ステップ 3: アクションをコンポーネントに接続

ユーザーのフロントエンド入力を API に渡すには、{{ を使用してコンポーネントに入力されたデータを取得できます。 例えば、input2 は質問を入力するためのコンポーネントであり、input1 は入力コンテキストへのコンポーネントです。 キーに `question` と `context` を入力し、値に `{{ input.value }}` を入力します。

```jsx
{
"question": {{input2.value}},
"context": {{input1.value}}
}
```

Actionの出力データをフロントエンドコンポーネントに表示する前に、異なるモデルの出力がどのフィールドに配置されているかを確認する必要があります。 まだ `deepset/roberta-base-squad2` を例にとってみると、結果は以下のとおりです。

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi8.png' alt="" />

ですから、`{{ textQuestion.data[0].answer }}`（`textQuestion`はアクションの名前です）で答えを得ることができます。 

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi9.png' alt="" />

### デモ

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi10.gif' alt="" />

<img src='https://cdn.illacloud.com/official-website/img/docs/connect/hfapi11.gif' alt="" />
